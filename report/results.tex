\section{Results} \label{sec:results}

We have finally reached the point where we can determine the unbiased accuracy
our different models. To do this we will make use of the (D) dataset. Just
to reiterate the details contained in Section \ref{sec:data}, this data set
consists of last 3558 authors available to us, where none of these authors are
repeated in any of the other sets.

We have 5 models which we are going to apply to this test dataset,
our two baseline methods, the character-level \gls{CNN}, the sentence
level RNN, and the character-word-level \gls{CNN}.

Starting with the baseline methods, we made use of the features and the
hyper parameters that provided best on the training set.
For the Extended Delta method, this was a K value, and a p value of 1.
Then using the same sample generation as was described in the bottom
of Section \ref{sec:hyp_select}, and normalizing using the scaler
produced when generating the features, we applied were able to apply the model.
The same was done with the SVM, where we used to optimal found hyperparameters,
$C=10$ and $\gamma = 1000$, to train the model. The results can be seen in Table
\ref{tab:baseline-res}.

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c||c|c|}
\hline
Split & Classifier & Params & TPS & TNS & FPS & FNS & \textbf{Acc} & \textbf{A-Error} \\ \hline
\multirow{2}{*}{50/50} & SVM & \{C:10, $\gamma$:1000\} & 2667 & 2442 & 1100 & 883 & \textbf{0.71958} & \textbf{0.26556} \\ \cline{2-9} 
 & ED & \{K:1, p:1\} & 2349 & 2064 & 1486 & 1201 & \textbf{0.62155} & \textbf{0.36784} \\ \hline
\multirow{2}{*}{96/04} & SVM & \{C:10, $\gamma$:1000\} & 2629 & 98 & 57 & 921 & \textbf{0.73723} & \textbf{0.90382} \\ \cline{2-9} 
 & ED & \{K:1, p:1\} & 2369 & 92 & 56 & 1181 & \textbf{0.66549} & \textbf{0.92773} \\ \hline
\end{tabular}
\caption{The results of running our baseline methods on the test dataset (D), with the optimal hyper
parameters, on both a 50/50 dataset and 96/04 one}
\label{tag:baseline-res}
\end{table}

With this we have our baseline to beat. As briefly mentioned in Section
\ref{subsec:baseline}, these method are not very well suited for this particular
task. Since they both provide binary results denoting a students innocence, or
lack thereof, it is not possible to apply any kind of thresholding to force
our models under the 10\% accusation error goal. They always perform at their
maximum capacity. For this reason we had to alter they way we compare the deep
learning approaches with our baselines. This was done by determining the beast
performing $\theta$ and weight function for our neural network with
regard to accuracy, and with no regard to the accusation error, as both
our baselines do not focus on that either. Thus we compared the
results of our base lines on the 50/50 dataset and the 96/04 dataset
with the highest unconstrained accuracy our deep learning methods could
muster.

Finding and computing these values for \gls{conv-char-NN},
using the test dataset D, yielded the results seen in Table \ref{tab:char_CNN_res}

\begin{table}[h]
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
Split & Allowed Err & Weight & $\theta$ & TPS & TNS & FPS & FNS & \textbf{Acc} & \textbf{A-Error} \\ \hline
\multirow{2}{*}{50/50} & 0.1 & $P_{lexp_{0.25}}$ & 0.390 & 3392 & 2344 & 1206 & 158 & \textbf{0.80788} & \textbf{0.0631} \\ \cline{2-10} 
 & 1.0 & $P_{lexp_{0.25}}$ & 0.486 & 3231 & 2913 & 637 & 319 & \textbf{0.86535} & \textbf{0.0987} \\ \hline
\multirow{2}{*}{96/04} & 0.1 & $P_{MV}$ & 0.057 & 3546 & 13 & 140 & 4 & \textbf{0.96111} & \textbf{0.2352} \\ \cline{2-10} 
 & 1.0 & $P_{lexp_{0.25}}$ & 0.137 & 3540 & 28 & 125 & 10 & \textbf{0.96354} & \textbf{0.2631} \\ \hline
\end{tabular}
\caption{The result of running the network \gls{conv-char-NN} on the dataset (D). Contraint
denotes if the hyperparameters, weight and $\theta$ was chosen base on their
unconstrained accuracy or constrained, making unconstrained results the one for 
comparison with the baseline method. A-Error denotes the accusation error.}
\label{tab:char_CNN_res}
\end{table}
