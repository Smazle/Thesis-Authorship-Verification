\section{Results} \label{sec:results}

We have finally reached the point where we can determine the unbiased accuracy
our different models. To do this we will make use of the (D) dataset. As
mentioned in Section \ref{sec:data}, this data set consists of 3558 authors,
none of which are repeated in any of the other sets.

We have 5 models which we are going to apply to this test dataset, our
two baseline methods, the \gls{conv-char-NN}, the \gls{rec-sent-NN} , and the
\gls{conv-char-word-NN}.

Starting with the baseline methods, we made use of the features and the
hyper parameters that provided best on the training set. For the Extended
Delta method, the optimal parameters were $K=1$ and $p = 1$. Then using
the same sample generation as was described in the bottom of Section
\ref{sec:hyp_select}, and normalizing using the scaler produced when
generating the features, we applied were able to apply the model. The same
was done with the SVM, where we used the optimal found hyperparameters, $C=10$
and $\gamma = 1000$, to train the model. The results can be seen in Table
\ref{tab:baseline-res}.

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c||c|c|}
\hline
Split & Classifier & Params & TP & TN & FP & FN & \textbf{Acc} & \textbf{A-Error} \\ \hline
\multirow{2}{*}{50/50} & SVM & \{C:10, $\gamma$:1000\} & 2667 & 2442 & 1100 & 883 & \textbf{0.71958} & \textbf{0.26556} \\ \cline{2-9} 
 & ED & \{K:1, p:1\} & 2349 & 2064 & 1486 & 1201 & \textbf{0.62155} & \textbf{0.36784} \\ \hline
\multirow{2}{*}{96/04} & SVM & \{C:10, $\gamma$:1000\} & 2629 & 98 & 57 & 921 & \textbf{0.73723} & \textbf{0.90382} \\ \cline{2-9} 
 & ED & \{K:1, p:1\} & 2369 & 92 & 56 & 1181 & \textbf{0.66549} & \textbf{0.92773} \\ \hline \end{tabular}
\caption{The results of running our baseline methods on the test dataset (D),
with the optimal hyper parameters, on both a 50/50 dataset and 96/04 one. ED in
the classifier column, denotes the Extended delta method, and SVM the support
vector machine method.}
\label{tab:baseline-res}
\end{table}

With this we have our baseline to beat. As briefly mentioned in Section
\ref{subsec:baseline_methods}, these method are not very well suited for this
particular task. Since they both provide binary results denoting a students
innocence, or lack thereof, it is not possible to apply any kind of thresholding
to force our models under the 10\% accusation error goal. They always perform at
their maximum capacity. For this reason we had to alter they way we compare the
deep learning approaches with our baselines. This was done by determining the
best performing $\theta$ and weight function for our neural network with regard
to accuracy, and with no regard to the accusation error, as both our baselines
do not focus on that either. Thus we compared the results of our base lines on
the 50/50 dataset and the 96/04 dataset with the highest unconstrained accuracy
our \gls{NN} methods could muster.

After determining the best networks using the dataset (E) in conjunction with
dataset (F), we proceeded to train the three networks on the entire dataset (B)
using dataset (C) as the validation set used throughout the training. Doing
this, was all for the sake of providing more data for the final models, before
applying them to the (D) test dataset.

Having now trained the models we can determine the accuracy and accusation
error of our different networks, both with and without the 10\% accusation error
constraint.

Doing this for the network \gls{conv-char-NN}, using the test dataset D, yielded
the results seen in Table \ref{tab:char_CNN_res}

\begin{table}[]
\begin{tabular}{|c|c|c|c|c|c|c|c||c|c|}
\hline
Split & Constrained & Weight & $\theta$ & TP & TN & FP & FN & \textbf{Acc} & \textbf{A-Error} \\ \hline
\multirow{2}{*}{50/50} & Yes & $P_{lexp_{0.25}}$ & 0.390 & 3392 & 2344 & 1206 & 158 & \textbf{0.80788} & \textbf{0.0631} \\ \cline{2-10} 
 & No & $P_{lexp_{0.25}}$ & 0.486 & 3231 & 2913 & 637 & 319 & \textbf{0.86535} & \textbf{0.0987} \\ \hline
\multirow{2}{*}{96/04} & Yes & $P_{MV}$ & 0.057 & 3546 & 13 & 140 & 4 & \textbf{0.96111} & \textbf{0.2352} \\ \cline{2-10} 
 & No & $P_{lexp_{0.25}}$ & 0.137 & 3540 & 28 & 125 & 10 & \textbf{0.96354} & \textbf{0.2631} \\ \hline
\end{tabular}
\caption{The result of running the network \gls{conv-char-NN} on the dataset
(D). Split denotes the split between negative and positive samples in the
generated test sample set. Allowed Err, denotes if the parameters, weight
method, and $\theta$ was selected based on their ability accusation error under
0.1 or just their accuracy. A-Error denotes the accusation error.}
\label{tab:char_CNN_res}
\end{table}

We also used that same approach for the other two networks, resulting in what
can be seen in Table \ref{tab:char_word_CNN_res}, which is the test results of
\gls{conv-char-word-NN}, and in Table \ref{tab:RNN_res}, which contains the
results from \gls{rec-sent-NN}.

\begin{table}[]
\begin{tabular}{|c|c|c|c|c|c|c|c||c|c|}
\hline
Split & Constrained & Weight & $\theta$ & TP & TN & FP & FN & \textbf{Acc} & \textbf{A-Error} \\ \hline
\multirow{2}{*}{50/50} & Yes & $P_{lexp_{0.25}}$ & 0.433 & 3185 & 2512 & 1038 & 36 & \textbf{0.80239} & \textbf{0.1268} \\ \cline{2-10} 
 & No & $P_{lexp_{0.25}}$ & 0.544 & 2810 & 3088 & 462 & 740 & \textbf{0.83070} & \textbf{0.1933} \\ \hline
\multirow{2}{*}{96/04} & Yes & $P_{exp_{0.25}}$ & 0.127 & 3516 & 32 & 112 & 34 & \textbf{0.96047} & \textbf{0.5151} \\ \cline{2-10} 
 & No & $P_{lexp_{0.25}}$ & 0.192 & 3507 & 47 & 97 & 43 & \textbf{0.96210} & \textbf{0.4777} \\ \hline
\end{tabular}
\caption{The result of running the network \gls{conv-char-word-NN} on the
dataset (D). Split denotes the split between negative and positive samples in
the generated test sample set. Allowed Err, denotes if the parameters, weight
method, and $\theta$ was selected based on their ability accusation error under
0.1 or just their accuracy. A-Error denotes the accusation error.}
\label{tab:char_word_CNN_res}
\end{table}

\begin{table}[]
\begin{tabular}{|c|c|c|c|c|c|c|c||c|c|}
\hline
Split & Constrained & Weight & $\theta$ & TP & TN & FP & FN & \textbf{Acc} & \textbf{A-Error} \\ \hline
\multirow{2}{*}{50/50} & Yes & $P_{lexp_{0.25}}$ & 0.033 & 3182 & 1470 & 2080 & 368 & \textbf{0.65521} & \textbf{0.2002} \\ \cline{2-10} 
 & No & $P_{lexp_{0.25}}$ & 0.267 & 1795 & 3076 & 474 & 1755 & \textbf{0.68605} & \textbf{0.3632} \\ \hline
\multirow{2}{*}{96/04} & Yes & $P_{lexp_{0.25}}$ & 0.002 & 3505 & 18 & 130 & 45 & \textbf{0.95267} & \textbf{0.7142} \\ \cline{2-10} 
 & No & $P_{lexp_{0.25}}$ & 0.002 & 3505 & 18 & 130 & 45 & \textbf{0.95267} & \textbf{0.7142} \\ \hline
\end{tabular}
\caption{The result of running the network \gls{rec-sent-NN} on the
dataset (D). Split denotes the split between negative and positive samples in
the generated test sample set. Allowed Err, denotes if the parameters, weight
method, and $\theta$ was selected based on their ability accusation error under
0.1 or just their accuracy. A-Error denotes the accusation error.}
\label{tab:RNN_res}
\end{table}


