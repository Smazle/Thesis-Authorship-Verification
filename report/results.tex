\section{Results} \label{sec:results}

We have finally reached the point where we can determine the unbiased accuracy
of our different models. To do this we will make use of the \gls{D} dataset. As
mentioned in Section \ref{sec:data}, this dataset consists of 3558 authors, none
of which are repeated in any of the other sets.

We have 5 models which we are going to apply to this test dataset, our
two baseline methods, the \gls{conv-char-NN}, the \gls{rec-sent-NN} , and the
\gls{conv-char-word-NN}.

Starting with the baseline methods, we made use of the features and the
hyper parameters that provided best on the training set. For the extended
delta method, the optimal parameters were $K=1$ and $p = 1$. Then using
the same sample generation as was described in the bottom of Section
\ref{sec:hyp_select}, and normalizing using the scaler produced when generating
the features, we applied were able to apply the model. The same was done with
the \gls{SVM}, where we used the optimal found hyperparameters, $C=10$ and
$\gamma = 1000$, to train the model.

As briefly mentioned in Section \ref{subsec:baseline_methods}, these methods are
not very well suited for this particular task. Since they both provide binary
results denoting a students' innocence, or lack thereof, it is not possible to
apply any kind of thresholding to force our models under the 10\% accusation
error goal. They always perform at their maximum capacity. For this reason we
had to alter the way we compare the deep learning approaches with our baselines.
This was done by determining the best performing threshold ($\theta$) and weight
function for our neural network with regard to accuracy, and with no regard to
the accusation error, as both our baselines do not focus on that either. Thus we
compared the results of our baselines on the 50/50 dataset and the 96/04 dataset
with the highest unconstrained accuracy our \gls{NN} methods could muster.

After determining the best networks using the dataset \gls{E} in conjunction
with dataset \gls{F}, we proceeded to train the three networks on the entire
dataset \gls{B} using dataset \gls{C} as the validation set used throughout the
training. Doing this, was all for the sake of providing more data for the final
models, before applying them to the \gls{D} test dataset.

Having now trained the models we can determine the accuracy and accusation error
of our different networks, both with and without the 10\% accusation error
constraint. It should be noted that the parameters found that adhere to to the
10\% constraint were found on the training data. As with any machine learning
approach, this does not ensure the same level of adherence on the test data.

We also used that same approach for the other two networks. The combined
results for the 50/50 split test dataset \gls{D} can be seen in Table
\ref{tab:50_results}, and the results for the 96/04 split data can be seen in
table \ref{tab:04_results}.

\begin{table}[]
\centering
\textbf{The results of running our methods on a 50/50 split test dataset}\par\medskip
\begin{tabular}{|c|l|c|c|c|c|c|c|c|c|}
\hline
Bound                & Method                  & Weight            & $\theta$ & TP  & TN  & FP  & FN  & Acc             & A-Error         \\ \hline
\multirow{5}{*}{Yes} & SVM                     & \multicolumn{8}{c|}{N/A}                                                                     \\ \cline{2-10} 
                     & Extended Delta          & \multicolumn{8}{c|}{N/A}                                                                     \\ \cline{2-10} 
                     & \gls{conv-char-NN}      & $P_{lexp_{0.25}}$ & 0.390    & 3392 & 2344 & 1206 & 158  & \textbf{0.8078} & \textbf{0.0631} \\ \cline{2-10} 
                     & \gls{conv-char-word-NN} & $P_{lexp_{0.25}}$ & 0.433    & 3185 & 2512 & 1038 & 36   & 0.8023          & 0.1268          \\ \cline{2-10} 
                     & \gls{rec-sent-NN}       & $P_{lexp_{0.25}}$ & 0.033    & 3182 & 1470 & 2080 & 368  & 0.6552          & 0.2002          \\ \hline\hline
\multirow{5}{*}{No}  & SVM                     & N/A               & N/A      & 2667 & 2442 & 1100 & 883  & 0.7195          & 0.2656          \\ \cline{2-10} 
                     & Extended Delta          & N/A               & N/A      & 2349 & 2064 & 1486 & 1201 & 0.6215          & 0.3678          \\ \cline{2-10} 
                     & \gls{conv-char-NN}      & $P_{lexp_{0.25}}$ & 0.486    & 3231 & 2913 & 637  & 319  & \textbf{0.8653} & \textbf{0.0987} \\ \cline{2-10} 
                     & \gls{conv-char-word-NN} & $P_{lexp_{0.25}}$ & 0.544    & 2810 & 3088 & 462  & 740  & 0.8307          & 0.1933          \\ \cline{2-10} 
                     & \gls{rec-sent-NN}       & $P_{lexp_{0.25}}$ & 0.267    & 1795 & 3076 & 474  & 1755 & 0.6860          & 0.3632          \\ \hline
\end{tabular}
\caption{The results on the 50/50 dataset, using the listed methods.
\textit{Bound} refers to wether or not $\theta$ and the Weight which we used,
was chosen based on their accuracy bounded/constrained by a 0.1 accusation error.
In the case of Yes, it refers to under the 0.1 threshold and No refers to simply
maximizing accuracy with no regard for accusation error. In both case
the best results were bolded.}
\label{tab:50_results}
\end{table}

\begin{table}[]
\centering
\textbf{The results of running our methods on a 96/04 split test dataset}\par\medskip
\begin{tabular}{|c|l|c|c|c|c|c|c|c|c|}
\hline
Bound                & Method                  & Weight            & $\theta$ & TP  & TN & FP & FN  & Acc             & A-Error         \\ \hline
\multirow{5}{*}{Yes} & SVM                     & \multicolumn{8}{c|}{N/A}                                                                   \\ \cline{2-10} 
                     & Extended Delta          & \multicolumn{8}{c|}{N/A}                                                                   \\ \cline{2-10} 
                     & \gls{conv-char-NN}      & $P_{MV}$          & 0.057    & 3546 & 13  & 140 & 4    & \textbf{0.9611} & \textbf{0.2352} \\ \cline{2-10} 
                     & \gls{conv-char-word-NN} & $P_{exp_{0.25}}$  & 0.127    & 3516 & 32  & 112 & 34   & 0.9604          & 0.5151          \\ \cline{2-10} 
                     & \gls{rec-sent-NN}       & $P_{lexp_{0.25}}$ & 0.002    & 3505 & 18  & 130 & 45   & 0.9526          & 0.7142          \\ \hline\hline
\multirow{5}{*}{No}  & SVM                     & N/A               & N/A      & 2629 & 98  & 57  & 921  & 0.7372          & 0.9038          \\ \cline{2-10} 
                     & Extended Delta          & N/A               & N/A      & 2369 & 92  & 56  & 1181 & 0.66549         & 0.9277          \\ \cline{2-10} 
                     & \gls{conv-char-NN}      & $P_{lexp_{0.25}}$ & 0.137    & 3540 & 28  & 125 & 10   & \textbf{0.9635} & \textbf{0.2631} \\ \cline{2-10} 
                     & \gls{conv-char-word-NN} & $P_{lexp_{0.25}}$ & 0.192    & 3507 & 47  & 97  & 43   & 0.9621          & 0.4777          \\ \cline{2-10} 
                     & \gls{rec-sent-NN}       & $P_{lexp_{0.25}}$ & 0.002    & 3505 & 18  & 130 & 45   & 0.9526          & 0.7142          \\ \hline
\end{tabular}
\caption{The results on the 96/04 data set, using the listed methods.
\textit{Bound} refers to wether or not $\theta$ and the Weight which we used,
was chosen based on their accuracy bounded/constrained by a 0.1 accusation error.
In the case of Yes, it refers to under the 0.1 threshold and No refers to simply
maximizing accuracy with no regard for accusation error. In both case
the best results were bolded.}
\label{tab:04_results}
\end{table}
