\section{Method} \label{sec:method} 


\subsection{Baseline Methods}

In order to gauge the efficiency of our deep learning approaches, we have
chosen to implement some baseline methods. These methods were picked
based on their performance in a previous project written by us as well,
\cite{US}. Albeit that project was only concerned with English texts
provided by the \cite{pan:2015}, and \cite{pan:2014} text forensics tasks,
we hypothesize that the performance of these approaches will perform just
as well on Danish texts.


\subsubsection{Extended Delta Method}

One of the best performing methods of \cite{US}, was the extended delta method.
As the name suggests, the methods serves to extend the already existing delta
method described by \cite{evert2015towards}. The normal delta methods consists
of first extracting the word frequencies from a newly introduced text, using
these as the describing feature. After doing this to the entire sample-space of
texts, and applying a linear transformation to their respective feature-sets,
\gls{KNN} is then used to determine the author of the introduced texts, based on
its' neighbors in the word-frequency feature-space. The extended delta method,
simply expands on the set possible features to pick from, rather than being
limited to only using the word-frequencies of the text.


\subsubsection{Author Specific SVM}

Another efficient algorithm used in \cite{US}. Heavily inspired by
\cite{hansen2014}, the approach starts out by fetching all texts known the
written by a specific author, and a equal number of texts known not to be
written by that same author. It is upon the feature-set extracted from these
texts, that a \gls{SVM} is trained, allowing it to learn the specifics authors
writing style from the known texts supplied, and, in contrast, what the writing
style of someone not him is. When a new text, with disputed authorship, is then
set forth the ambition is that the trained \gls{SVM} will be able to determine
if the author it was trained on, is in fact the author of this new text as well.



TODO: Describe how our first architecture was inspired by \cite{qian:2018} but
instead of using the cosine difference on top of the NN extracting features, we
used a dense neural network to compare the output.

\begin{itemize}
    \item Replace escaped characters in MaCom data.
    \item Convert all characters in text to numbers such that we have lists of
        numbers.
    \item Convert list of numbers to list of one hot encoded vector where each
        character has a different vector.
    \item Pad all texts with zeroes such that all texts has the same length.
    \item Make random dataset of size n by making (n/2) rows containing two
        padded texts from the same author and the class 1 and making (n/2) rows
        containing two texts from different authors and the class 0.
    \item Feed the problems to a neural network that looks like this,

        \begin{lstlisting}
     |Text 1|          |Text 2|
        |                 |
        |                 |
      | Convolutional Layer(s) |
          |                 |
          |                 |
  | GlobalMaxPool | | GlobalMaxPool |
          |                 |
          |                 |

    |     Dense Layer(s)        |
                |
                |
| Same/Different Author Probabilities |
        \end{lstlisting}

        The number of filters in the convolutional layers determines the number
        of outputs of the GlobalMaxPools. The output of the GlobalMaxPools
        represents the input text and the dense layers then have to compare the
        two representations to find whether or not they are written by the same
        author.

        The convolutional layers look at some number of characters at a time and
        the hope is then that they will learn the important n-grams.

    \item Try the delta method and our SVM method as a baseline for the neural
        networks.

\end{itemize}

TODO:

\begin{itemize}
    \item Describe preprocessing.
\end{itemize}
