% Introduction should be written in the present tense!
%
% Your introduction needs to include background information which is generally
% accepted as fact in a discipline. You also need to explain why the research
% you are reporting is important. It is usually presented in the present tense.
%   - https://services.unimelb.edu.au/__data/assets/pdf_file/0009/471294/Using_tenses_in_scientific_writing_Update_051112.pdf

\section{Introduction} \label{sec:introduction}

% An introduction to the context or background of the topic (you could include
% interesting facts or quotations)

In this thesis we work on the problem of authorship verification using texts
written by Danish secondary school pupils. Authorship verification and
authorship attribution is the ability to distinguish between authors of texts
based on a set of extracted textual features. The automation of authorship
attribution/verification has been a lively branch of research ever since the
beginning of the digital age, giving birth to online digital text forensics
tasks, such as the work by \citet{pan:2015}. Initial attempts at quantifying
writing style can be seen in \citet{Mendenhall237}, who attempted to determine
the authorship of several of Shakespeare's texts. There is a theory that
Shakespeare did not write some or all of his texts, or that he was a synonym
for one of more more unknown authors. \citet{Mendenhall237} attempted this
classification using the frequency distribution of words of different lengths.
Throughout the years the approaches to this problem have changed quite a bit.
When authorship attribution started to interest researchers the approaches were
Stylometric i.e. they were based on the linguistic style of authors. In addition
to that, fully automated systems were rare and was mostly used in a supporting
manner. It was during the 1990's that fully automated systems became more
prevalent. The main reason for this was the Internet. Before the Internet, the
data available simply was not suitable for authorship attribution tasks. Books
were too big, resulting in a lack in homogeneity, and the amount of authors and
bench-marking data was too small. The Internet paved the way for insurmountable
amounts of data and variations of that data, impacting areas such as information
retrieval, machine learning and \gls{NLP}.

In order for any fully automatic authorship verification to work, stylometric
features describing the text has to be automatically extracted. These features
span multiple linguistic layers, ranging from the low level character n-grams
to the high level application specific features such as text creation date and
number of edits. Many of the current day state-of-the-art approaches are based
on these features.

% The reason for writing about this topic:

We want to experiment with and solve an authorship verification task for the
Danish company \texttt{MaCom A/S} \footnote{\url{http://www.macom.dk/}}.
MaCom is the company behind the product \texttt{Lectio}
\footnote{\url{https://www.lectio.dk/}}, which is a website that allows for
student administration, communication, and digital teaching aid. Lectio is used
in schools all over Denmark. A service the website offers is the submission
and handling of assignments written by students throughout their enrollment.
MaCom has shown interest in determining whether or not these assignment
were written by someone other than the student (a ``ghost writer''). Ghost
writing is especially a problem on the \gls{SRP} assignment. \gls{SRP} is
an interdisciplinary assignment all Danish secondary school students turn
in at the end of their third year. There is no oral examination for the
assignment and the grade obtained is part of the students final results from
the secondary school. The combination of the importance of the assignment
and no oral examination leads to students turning in assignments written by
ghost writers. The Danish state owned public service radio and television
company \texttt{DR} has written an article describing the ghost writer problem
\footnote{\url{https://www.dr.dk/nyheder/indland/elever-bruger-ghostwritere-til-
eksamen}}. The article describes that when asking 2000 student, 58\% got help
from friends or family, and around 15\% knew someone who had their assignment
written by someone else. In this thesis we setup a system for detecting ghost
writing based on machine learning methods. The system is meant to help teachers
make decisions about whether or not an assignment turned in by a student is
written by someone else. It is not important that the system catches 100\% of
the assignments written by someone else. If the system only catches a fraction
of the cheaters, it will deter other students from cheating. What is most
important is that the system does not accuse anyone of cheating who has turned
in their own assignment. The system should also be able to give evidence for why
we think a particular assignment is written by someone else. Such evidence could
for example be that the frequency of particular words is significantly different
in the new assignment than in all previously handed in by the student. Evidence
for why we think an assignment is written by someone else will help a teacher if
he/she wants to accuse a student of using a ghost writer.

% Introduce the main ideas that stem from your topic/title and the order in
% which you will discuss them?

As described the problem main problem we try to solve in this thesis is
authorship verification which is defined below.

\begin{definition}[Authorship Verification]
    \label{def:authorship_verification}

    Given a set of texts $T_\alpha$ written by author $\alpha$ and a single
    text $x$ of unknown authorship, determine if $x \in T_\alpha$.

\end{definition}

Authorship verification is closely linked with the problem of authorship
attribution as can be seen in the definition of authorship attribution shown
below.

\begin{definition}[Authorship Attribution]

    Given a set of authors $\mathcal{A} = \{ \alpha_1, \alpha_2,...\alpha_N\}$,
    each with set of text $T_{\alpha_i}$, and a text of unknown authorship
    \texttt{x}, determine which $\alpha_i \in \mathcal{A}$ is the author of
    \texttt{x}.

\end{definition}

The problems are closely linked since an answer for authorship attribution
can be obtained by using authorship verification and an answer for authorship
verification can be obtained by using authorship attribution. Consider a case
where we are given an oracle answering the authorship verification problem
$\mathcal{S}$. $\mathcal{S}$ is a mapping from an author $\alpha$ and text
$x$ to either true or false. Given an instance of the authorship attribution
problem with authors $\mathcal{A}$ and text $x$ we solve the problem by using
$\mathcal{S}$ on each author $\alpha \in \mathcal{A}$. We return the author
where $\mathcal{S}$ reports true. Now consider a case where we are given a
solution to the authorship attribution problem $\mathcal{S}'$. $\mathcal{S}'$
is now a mapping from a set of authors $\mathcal{A}$ and text $x$ to an author
$\alpha \in \mathcal{A}$. Given an instance of the authorship verification
problem with author $\alpha_i \in \mathcal{A}$ and text $x$ and a set of texts
written by different authors $\overline{T}_{\alpha} = \bigcup_{\beta \in A
\setminus \{\alpha\}} T_\beta$ we solve the verification problem by applying the
attribution function to the texts $T_{\alpha} \cup \overline{T}_{\alpha}$ and
the text of unknown authorship $x$. If $x \in T_{\alpha}$ we report true and
otherwise false.
