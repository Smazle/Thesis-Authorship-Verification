% TODO: Update these numbers when we are given new datasets.
\section{Data} \label{sec:data}

As described earlier we use data from the Danish company MaCom. The dataset
provided by MaCom is a file consisting of set of texts in Danish where each text
is associated with an author ID. We have been given several text extractions
of different sizes with the biggest dataset consisting of 32,682 texts. The
dataset consist of texts of many different sizes. The shortest text consist of 2
characters and the longest text of 1,899,065 characters. The average length of
each text is 5851 characters with a median of 5548 characters. That means that
almost all texts is close to the average and only a few has sizes much greater
or smaller than the average. The dataset contains 2047 different authors with
an average of 16 texts. The author with the smallest amount of text has two
texts and the author with the most amount of text has 33 texts.

% TODO: Describe why we chose 1 / 100000.
In several of our experiments we limited the number of different characters we
represented. We did that to simplify the amount of different characters our
neural networks had to consider. In particular we cutoff any characters that
occurred with a frequency less than $\frac{1}{100,000}$. We wanted to make sure
that the cutoff only removed characters that were so infrequent that it would be
hard for the neural networks to learn anything from them. Since the average
amount of characters in a single text were 5851 characters most texts wont
include any character that has a frequency below the above cutoff point. While
we wanted to limit the number of different characters the network would have to
consider we also wanted to make sure that a couple of Danish characters would be
considered. In particular the characters \ae, \o, \aa, \AE, \O\ and \AA. Those
characters occur with the frequencies TODO, TODO, TODO, TODO, TODO and TODO and
they will therefore all be included.

% TODO: Describe how we dealt with garbage texts.
The texts we are given are extracted from \textit{.pdf} files and there will
therefore sometimes be garbage included.
