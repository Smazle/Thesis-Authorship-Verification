\documentclass[10pt]{beamer}

\usetheme[progressbar=frametitle]{metropolis}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{appendixnumberbeamer}
\usepackage{booktabs}
\usepackage[scale=2]{ccicons}
\usepackage{pgfplots}
\usepgfplotslibrary{dateplot}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{bbm}

\newcommand{\themename}{\textbf{\textsc{metropolis}}\xspace}

\title{Authorship Verification}
\subtitle{Masters Thesis}
\date{}
\author{Magnus Stavngaard}
\institute{University of Copenhagen}

\defbeamertemplate{description item}{align left}{\insertdescriptionitem\hfill}

\begin{document}

\maketitle

\begin{frame}[fragile]{Problem Statement}
    \begin{definition}[Authorship Verification]
        \label{def:authorship_verification}

        Given a set of texts $T_\alpha$ written by author $\alpha$ and a
        single text $t$ of unknown authorship, determine if $\alpha$ is
        the author of $t$.

    \end{definition}

    \begin{itemize}
        \item Use data from MaCom (Lectio) used by more than 90\% of Danish
            Secondary Schools.
        \item 4\% of SRP assignments are ghostwritten.
        \item Accusation error less than 10\% while catching 95\% of
            ghostwriters.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Baselines}
    \begin{itemize}
        \item Classical machine learning authorship verification methods use
            hand engineered feature sets.
        \item Delta method are a distance function between vectors of feature
            frequencies. Closest author is considered the author of the text.
        \item SVM classifier are trained on feature vector of $T_\alpha$ and
            $\overline{T_\alpha}$.
        \item Features are frequencies of
            \begin{itemize}
                \item character-n-grams ([h, e, l, l, o]),
                \item special-character-n-grams ([!, ., ?]),
                \item word-n-grams ([Hello, World]) and
                \item pos-tag-n-grams ([noun, verb, verb, adjective]).
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Siamese Networks}
    \begin{itemize}
        \item Siamese Neural Networks compares two objects.

            \begin{description}
                \item[Input] Two objects,
                \item[Output] Probability that objects belong to same class.
            \end{description}
    \end{itemize}

    \begin{center}
        \includegraphics[width=0.6\textwidth]{../../report/pictures/method/siamese}
    \end{center}
\end{frame}

\begin{frame}[fragile]{Networks}
    \setbeamertemplate{description item}[align left]
    \begin{itemize}
        \item Networks consist of 4 parts:

            \begin{description}
                \item[Embedding] Encode raw text in format to be used by
                    networks.
                \item[Feature Extraction] Extract feature vectors from the
                    encoded texts.
                \item[Combining] Combine extracted feature vectors using some
                    function.
                \item[Decision] Define whether or not the combined feature
                    vectors are similar or dissimilar.
            \end{description}

        \item Weight sharing is in embedding and feature extraction.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Char-CNN}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{../../report/pictures/experiments/conv_char_nn/model}
    \end{center}
\end{frame}

\begin{frame}[fragile]{Sent-RNN}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{../../report/pictures/experiments/rec_sent_nn/model}
    \end{center}
\end{frame}

\begin{frame}[fragile]{Char-word-CNN}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{../../report/pictures/experiments/conv_char_word_nn/model}
    \end{center}
\end{frame}

\begin{frame}[fragile]{Combining Network Output}
    \begin{itemize}
        \item We combine the output of the network on texts using prediction
            systems,

        \begin{align*}
            &P_w \colon \mathcal{A} \times \mathcal{T} \times [0, 1] \rightarrow
                \{0, 1\} \\
            &P_w(\alpha, t, \theta) \mapsto \mathbbm{1}\left[
                    \sum_{t' \in T_\alpha} w(t') f(t, t') > \theta
                \right].
        \end{align*}

        \item We find best prediction system configuration via,

        \begin{equation*}
            \begin{aligned}
                & \underset{\theta, x}{\text{minimize}}
                & & \sum_{(\alpha, t_u) \in V} \left|
                    P_x(T_\alpha \setminus \{t_u\}, t_u, \theta) -
                    \mathbbm{1}\left[t_u \in T_\alpha\right]
                \right| \\
                & \text{subject to}
                & & \frac{\sum_{(\alpha, t_u) \in V} \mathbbm{1}\left[t_u \in T_\alpha\right] \cdot
                    \left(1 - P_x(T_\alpha \setminus \{t_u\}, t_u, \theta)\right)}
        {\sum_{(\alpha, t_u) \in V} (1 - P_x(T_\alpha \setminus \{t_u\}, t_u, \theta)} <
                    \frac{1}{10}.
            \end{aligned}
        \end{equation*}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Prediction Systems}
    \begin{center}
        \includegraphics[width=\textwidth]{../../report/pictures/experiments/conv_char_nn/prediction_system_50}
    \end{center}
\end{frame}

\begin{frame}[fragile]{Baseline Comparison}
    \begin{itemize}
        \item Unconstrained 4\% results.
            \begin{center}
                \begin{tabular}{c|ccc}
                    \textbf{Method}      & \textbf{Accusation Error} &
                    \textbf{Specificity} & \textbf{Accuracy}
                    \\ \hline
                    Extended Delta       & 92.8\%                    &
                    62.0\%               & 66.5\%
                    \\
                    SVM                  & 90.4\%                    &
                    63.2\%               & 73.7\%
                    \\
                    Char-CNN             & 26.3\%                    &
                    18.3\%               & 96.4\%
                    \\
                    Sent-RNN             & 71.4\%                    &
                    12.2\%               & 95.3\%
                    \\
                    Char-word-CNN        & 47.8\%                    &
                    32.6\%               & 96.2\%
                \end{tabular}
            \end{center}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Comparison to Previous Work}
    \begin{itemize}
        \item Unconstrained 50\% results.
            \begin{center}
                \begin{tabular}{c|ccc}
                    \textbf{Method}      & \textbf{Accusation Error} &
                    \textbf{Specificity} & \textbf{Accuracy}
                    \\ \hline
                    Char-CNN             & 9.9\%                     &
                    82.1\%               & 86.5\%
                    \\
                    Sent-RNN             & 36.3\%                    &
                    86.6\%               & 68.6\%
                    \\
                    Char-word-CNN        & 19.3\%                    &
                    87.0\%               & 83.1\%
                    \\
                    Hansen et al.        &                           &
                                         & 84.0\%
                    \\
                    Aalykke              & 5.0\%                     &
                    71.9\%               & 83.5\%
                    \\
                \end{tabular}
            \end{center}
        \item Aalykke used only SRP assignments which are longer.
        \item Like Hansen we found using time works.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Results}
    \begin{itemize}
        \item Constrained 4\% results.
            \begin{center}
                \begin{tabular}{c|ccc}
                    \textbf{Method}      & \textbf{Accusation Error} &
                    \textbf{Specificity} & \textbf{Accuracy}
                    \\ \hline
                    Char-CNN             & 23.5\%                    &
                    8.5\%                & 96.1\%
                    \\
                    Sent-RNN             & 71.4\%                    &
                    12.2\%               & 95.3\%
                    \\
                    Char-word-CNN        & 51.5\%                    &
                    22.2\%               & 96.0\%
                \end{tabular}
            \end{center}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Teacher Feedback}
    \begin{center}
        \includegraphics[width=\textwidth]{../../report/pictures/discussion/teacher_feedback_example}
    \end{center}
\end{frame}

\begin{frame}[fragile]{Teacher Feedback}
    \begin{center}
        \scriptsize
        \begin{tabular}{lll|lll}
            \textbf{Max 1}    & \textbf{Max 2}    & \textbf{Max 3}       &
            \textbf{Text 1}   & \textbf{Text 2}   & \textbf{Difference}  \\
            \hline
            \verb[nemlig 1[   & \verb[nemlig 1[   & \verb[nemlig –[      &
            \verb'pere.\n\nH' & \verb'nemlig b'   & |3.06 - 4.70| = 1.64 \\

            \verb[, F.eks.[   & \verb[, F.eks.[   & \verb[, F.eks.[      &
            \verb'. F.eks.'   & \verb'del. Und'   & |4.73 - 3.18| = 1.55 \\

            \verb[ke …''. [   & \verb[a...''\n\n[ & \verb[n''. '' [      &
            \verb'v. Men d'   & \verb'n. Den v'   & |4.28 - 2.91| = 1.37 \\

            \verb[forsøger[   & \verb[forsøger[   & \verb[forsøger[      &
            \verb'for sætt'   & \verb'forsøgte'   & |3.40 - 4.77| = 1.37 \\

            \verb[, Hvorda[   & \verb[, Hvorda[   & \verb[,08 – 6,[      &
            \verb', som ti'   & \verb', Hvorda'   & |3.70 - 5.07| = 1.37 \\

            \verb[der; ’’M[   & \verb[der; ”Ha[   & \verb[der; ”Ma[      &
            \verb'dem; Nia'   & \verb'der omha'   & |4.64 - 3.28| = 1.36 \\

            \verb[. Her ef[   & \verb[. Her ef[   & \verb[' Her br[      &
            \verb'. Jeg vi'   & \verb'. Her fo'   & |2.61 - 3.92| = 1.31 \\

            \verb[r dog kr[   & \verb[r dog kr[   & \verb[r dog ’d[      &
            \verb'r og lud'   & \verb'r dog i '   & |2.83 - 4.13| = 1.30 \\

            \verb[11], da [   & \verb[:1], da [   & \verb[:1], da [      &
            \verb'ys”, der'   & \verb'for, da '   & |3.78 - 5.04| = 1.26 \\

            \verb[, så Car[   & \verb[, så Car[   & \verb[, så Car[      &
            \verb', så er '   & \verb', som En'   & |5.19 - 3.94| = 1.25 \\
            \hline
            \verb[; ’S[       & \verb[; ’S[       & \verb[; ’E[          &
            \verb'; Ni'       & \verb'r He'       & |3.12 - 1.78| = 1.34 \\

            \verb[; ”t[       & \verb[; ”t[       & \verb[; ”t[          &
            \verb'; ”H'       & \verb', ”j'       & |3.44 - 2.13| = 1.31 \\

            \verb[d.’ [       & \verb[d.’ [       & \verb[d.’ [          &
            \verb'ne-V'       & \verb'20’e'       & |1.75 - 2.77| = 1.02 \\

            \verb[1\n’’[      & \verb[1]’’[       & \verb[1]’’[          &
            \verb' l2-'       & \verb'720’'       & |1.75 - 2.71| = 0.96 \\

            \verb['Det[       & \verb['Det[       & \verb['Det[          &
            \verb'ndet'       & \verb' Det'       & |2.37 - 3.25| = 0.88 \\

            \verb[f 1"[       & \verb[f 1"[       & \verb[f 1"[          &
            \verb'f 2\n'      & \verb'v og'       & |3.05 - 2.20| = 0.85 \\

            \verb[æk''[       & \verb[’’ é[       & \verb[ud;'[          &
            \verb'lv; '       & \verb',tro'       & |2.60 - 1.77| = 0.83 \\

            \verb[\n\nx\n[    & \verb[\n\nx\n[    & \verb[\n\nx\n[       &
            \verb'\n\n\n\n'   & \verb'\n\n5\n'    & |1.81 - 2.61| = 0.80 \\
            \verb[ “… [       & \verb[ “… [       & \verb[?“! [          &
            \verb'nd” '       & \verb'r,” '       & |1.75 - 2.53| = 0.78 \\

            \verb[S\n, [      & \verb[S\n, [      & \verb[O\n, [         &
            \verb'e\n, '      & \verb'ad, '       & |2.62 - 1.92| = 0.70 \\
        \end{tabular}
    \end{center}
\end{frame}

\begin{frame}[fragile]{Conclusion}
    \begin{itemize}
        \item Did not perform as well as MaCom wanted.
        \item Best network achieved accusation error of 23.5\% while catching
            8.5\% of ghostwriters.
        \item Better results than previous work on MaCom dataset.
        \item We believe that with further work we would be able to get below
            the 10\% accusation error while catching 10-20\% of cheaters.
        \item Able to give teachers feedback.
    \end{itemize}
\end{frame}

\end{document}
